{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  加载外部数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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\n",
      "北京是中华人民共和国的首都。\n",
      "count(北京是哪个国家的首都) =10 \n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# 将数据切分成\n",
    "from dataclasses import dataclass, field\n",
    "from math import ceil, floor\n",
    "from enum import Enum\n",
    "from typing import List, Literal, TypedDict, Optional\n",
    "import tiktoken\n",
    "import openai\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "class MessageRole(Enum):\n",
    "    # chat role\n",
    "    User = \"user\"\n",
    "    System = \"system\"\n",
    "    Asisstant = \"asisstant\"\n",
    "    # inner role\n",
    "    You = \"you\"\n",
    "    YourComputer = \"your computer\"\n",
    "class MessageType(Enum):\n",
    "    AIResponse = \"ai_response\"\n",
    "    ActionResults = \"action_results\"\n",
    "\n",
    "\n",
    "# MessageRole = Literal[\"system\", \"user\", \"assistant\"]\n",
    "# MessageType = Literal[\"ai_response\", \"action_results\"]\n",
    "\n",
    "\n",
    "class MessageDict(TypedDict):\n",
    "    role: MessageRole\n",
    "    content: str\n",
    "@dataclass\n",
    "class Message:\n",
    "    role: MessageRole\n",
    "    content: str\n",
    "    # TODO msg_type 的意义是什么？\n",
    "    msg_type: Optional[MessageType] = None\n",
    "\n",
    "    def raw(self) -> MessageDict:\n",
    "        return {\"role\": self.role, \"content\": self.content}\n",
    "\n",
    "\n",
    "def count_message_tokens(messages: List[Message], model: str = \"gpt-3.5-turbo\") -> int:\n",
    "    encoding = tiktoken.encoding_for_model(model)\n",
    "    tokens_per_message = 3\n",
    "    tokens_per_name = 1\n",
    "    if model.startswith(\"gpt-3.5\"):\n",
    "        tokens_per_message = 4\n",
    "        tokens_per_name = -1\n",
    "    num_tokens = 0\n",
    "    for message in messages:\n",
    "        num_tokens += tokens_per_message\n",
    "        for key, value in message.raw().items():\n",
    "            num_tokens += len(encoding.encode(value))\n",
    "            if key == \"name\":\n",
    "                num_tokens += tokens_per_name\n",
    "    num_tokens += 3  # every reply is primed with <|start|> assistant<|message>\n",
    "    return num_tokens\n",
    "\n",
    "\n",
    "def count_string_tokens(string: str, model_name: str = \"gpt-3.5-turbo\") -> int:\n",
    "    encoding = tiktoken.encoding_for_model(model_name)\n",
    "    return len(encoding.encode(string))  \n",
    "\n",
    "\n",
    "def get_completion_from_messages(messages, model='gpt-3.5-turbo', temperature=0, max_tokens=2000):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature,\n",
    "        max_tokens=max_tokens,\n",
    "    )\n",
    "    return response.choices[0].message[\"content\"]\n",
    "\n",
    "def create_msg(msg:str):\n",
    "    \n",
    "    messages = [\n",
    "   \n",
    "        {\"role\": \"user\", \"content\": msg},\n",
    "    ]\n",
    "    return messages\n",
    "\n",
    "load_dotenv(\"../etc/dev/.env_new\")\n",
    "openai_api_key: str = os.getenv(\"OPENAI_API_KEY\")\n",
    "openai_api_key = \"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\"\n",
    "openai_api_key = \"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\"\n",
    "print(openai_api_key)\n",
    "openai.api_key = openai_api_key\n",
    "\n",
    "msg = \"北京是哪个国家的首都\"\n",
    "print(get_completion_from_messages(messages=create_msg(msg)))\n",
    "\n",
    "print(f'count({msg}) ={count_string_tokens(msg)} ')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加载KG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################行业分析 重点都有了DONE #########################\n",
    "# item\n",
    "kg_template_file ='./kg_un_formal/kg_industry_ana.txt'\n",
    "kg_input_for_ai_file = 'output/600271.kg_industry_ana_in_{}.txt'\n",
    "openai_out = 'output/600271.kg_industry_ana.openaiout.jsonl'\n",
    "openai_raw_out = 'output/600271.kg_industry_ana.openaiout.raw'\n",
    "# merge\n",
    "kg_merge_template_file = \"./kg_un_formal/kg_industry_ana_merge.txt\"\n",
    "kg_merge_input_for_ai_file = 'output/600271.kg_industry_ana_in_merge.txt'\n",
    "openai_merge_out = 'output/600271.kg_industry_ana.openaiout.merge.jsonl'\n",
    "openai_merge_raw_out = 'output/600271.kg_industry_ana.openaiout.merge.raw'\n",
    "\n",
    "# [\n",
    "#     {\"公司所处的行业是什么,公司从事哪些主要的什么业务\": \"公司所处的行业是数字政府、企业数字化产业，主要从事数字政府、企业财税服务、智慧业务和网信业务等主要业务。\"},\n",
    "#     {\"行业基本情况、周期性特点\": \"行业基本情况良好，数字经济发展大潮，国家支持度高，市场需求旺盛。\"},\n",
    "#     {\"公司所处的行业地位怎样？\": \"公司在所处行业具有一定的影响力和竞争力，拥有清晰的战略定位和明确的发展目标，具备完善的技术与产品体系，拥有国家和行业的完备顶级资质。\"},\n",
    "#     {\"最近是否有新的和公司所处行业相关的的法律、行政法规、部门规章、行业政策？这些内容对行业有什么影响\": \"最近没有提及新的与公司所处行业相关的法律、行政法规、部门规章、行业政策。\"},\n",
    "#     {\"管理层对行业格局和趋势的分析和展望是什么，公司在这种情况下的优势和劣势是什么\": \"内容中未提及管理层对行业格局和趋势的分析和展望，以及公司在这种情况下的优势和劣势。\"}\n",
    "# ]\n",
    "\n",
    "#############################公司竞争力分析 分片分析还行，汇总能力还是不行 DONE#####################\n",
    "kg_template_file ='./kg_un_formal/kg_company_core.txt'\n",
    "kg_input_for_ai_file = 'output/600271.kg_company_core_in_{}.txt'\n",
    "openai_out = 'output/600271.kg_company_core.openaiout.jsonl'\n",
    "openai_raw_out = 'output/600271.kg_company_core.openaiout.raw'\n",
    "# merge\n",
    "kg_merge_template_file = \"./kg_un_formal/kg_company_core_merge.txt\"\n",
    "kg_merge_input_for_ai_file = 'output/600271.kg_company_core_in_merge.txt'\n",
    "openai_merge_out = 'output/600271.kg_company_core.merge.jsonl'\n",
    "openai_merge_raw_out = 'output/600271.kg_company_core.openaiout.merge.raw'\n",
    "\n",
    "# ############################ 经营总结 要点似乎都在，都说的过去 ##########################\n",
    "kg_template_file ='./kg_un_formal/kg_operation.txt'\n",
    "kg_input_for_ai_file = 'output/600271.kg_company_core_in_{}.txt'\n",
    "openai_out = 'output/600271.kg_company_core.openaiout.jsonl'\n",
    "openai_raw_out = 'output/600271.kg_company_core.openaiout.raw'\n",
    "# merge\n",
    "kg_merge_template_file = \"./kg_un_formal/kg_operation_merge.txt\"\n",
    "kg_merge_input_for_ai_file = 'output/600271.kg_company_core_in_merge.txt'\n",
    "openai_merge_out = 'output/600271.kg_operation.merge.jsonl'\n",
    "openai_merge_raw_out = 'output/600271.kg_operation.openaiout.merge.raw'\n",
    "\n",
    "\n",
    "\n",
    "########################## 上下游风险 还行 ##########################\n",
    "kg_template_file ='./kg_un_formal/kg_key_danger.txt'\n",
    "kg_merge_template_file = \"./kg_un_formal/kg_key_danger_merge.txt\"\n",
    "openai_merge_out = 'output/600271.kg_key_danger.merge.jsonl'\n",
    "openai_merge_raw_out = 'output/600271.kg_key_danger.openaiout.merge.raw'\n",
    "\n",
    "########################  其他风险 比较简洁 ############################\n",
    "kg_template_file ='./kg_un_formal/kg_danger.txt'\n",
    "kg_merge_template_file = \"./kg_un_formal/kg_danger_merge.txt\"\n",
    "openai_merge_out = 'output/600271.kg_danger.merge.jsonl'\n",
    "openai_merge_raw_out = 'output/600271.kg_danger.openaiout.merge.raw'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "你是一个总结分析的专家，你要识别内容中务虚的内容，不要将这些内容放置在总结分析报告中。 \n",
      "例如：“加大研发投入、优化业务结构、提升整体竞争力、拓展境外市场、调整业务结构\n",
      "、加强技术创新、提升产品质量和服务水平、加强市场调研、优化产品和服务、灵活调整经营策略、加强研发投入、推动技术成果管理、加强国家级和省部级项目申报与建设、加快构建适应数字经济时代的市场营销体系、提升资本运作能力、\n",
      "持续加强队伍建设、强化风险合规管理、守稳守好大安全工作红线底线、加强顶层设计、完善营销组织体系建设、统筹国际、国内产业资源、完善产品体系建设、加强品牌建设与管理、强化营销队伍建设、推动产业协同发展等措施” \n",
      "每一个词组都是口号, 不具体。不能放置到总结分析中。\n",
      "\n",
      "请记住下面3个背景知识：\n",
      "  1. 供应商集中风险：\n",
      "     1.1 单一供应源风险：如果公司主要依赖一个或少数几个供应商，那么任何影响这些供应商的问题，如质量问题，生产中断，价格波动或破产，都可能对公司的运营产生重大影响。\n",
      "     1.2 议价能力下降：公司可能会因依赖少数供应商而失去谈判能力，导致可能无法获得最优的价格和条件。\n",
      "     1.3 创新能力下降：如果只依赖特定的供应商，公司可能会错过其他供应商可能提供的创新产品或服务。\n",
      "  2. 客户集中风险：\n",
      "     2.1 收入风险：如果公司的收入主要依赖于少数几个大客户，那么任何影响这些客户的问题，如财务困难，业务调整或破产，都可能对公司的销售和利润产生重大影响。\n",
      "     2.2 客户流失风险：如果主要客户转向竞争对手或选择不再使用公司的产品或服务，公司的收入可能会大幅下降。\n",
      "     2.3 议价能力下降：如果公司主要依赖少数几个大客户，这些客户可能会有更大的谈判力来要求更低的价格和更优的条款。\n",
      "  3. 关联公司作为供应商或客户可能带来冲突利益、法规、审计、信誉和市场风险。这些风险可能对公司的财务状况、合规性、声誉和业务多样性产生影响。\n",
      "\n",
      "  我将在后续提供一个管理层分析报告的内容片断，内容片断被```和````包含。\n",
      "请将上述背景知识作为总结和分析的原则， 对内容片断进行仔细思考，从如下4个方面来总结和分析公司的经营情况\n",
      " 每个方面的总结字数控制在50字以内, 采用务实客观严谨的新闻风格总结，提供关键的数据,案例支撑, 不要有抽象的口号，模糊的表述，不要猜想一些可能性：\n",
      "\n",
      "1. 供应商是否比较集中，如果有，管理层对此风险的解释是怎样的\n",
      "2. 客户是否比较集中，如果有，管理层对此风险的解释是怎样的\n",
      "3. 头部客户是否有关联公司,如果有，管理层对此风险的解释是怎样的\n",
      "4. 头部供应商是否有关联公司,如果有，管理层对此风险的解释是怎样的\n",
      "\n",
      "\n",
      "注意，所提供的内容并不能全部覆盖上述的4点内容。如果没有相关的内容就不要总结。例如没有提到第2点‘客户是否比较集中，如果有，管理层对此风险的解释是怎样的‘, 那么总结分析中就说“未提及相关内容，暂不分析“。 \n",
      "总结分析的输出格式为\n",
      "1. 供应商是否比较集中，如果有，管理层对此风险的解释是怎样的\n",
      "   xxxxx\n",
      "2. 客户是否比较集中，如果有，管理层对此风险的解释是怎样的\n",
      "   xxxxx\n",
      "3. 头部客户是否有关联公司,如果有，管理层对此风险的解释是怎样的\n",
      "   xxxxx\n",
      "4. 头部供应商是否有关联公司,如果有，管理层对此风险的解释是怎样的\n",
      "   xxxxx\n",
      "\n",
      "其中 xxxxx 是你需要总结的内容， 每个 xxxxx 控制在50字以内。 不要输出格式以外的内容。\n",
      "\n",
      " 再次强调，总结和分析要客观，不要猜想; 未提及的不要总结和分析。\n",
      " 提供关键的数据(例如大幅下降，需要指出下降多少),案例支撑, 不要有抽象的口号，模糊的表述，不要猜想一些可能性：\n",
      "\n",
      "\n",
      "管理层分析的内容片断如下\n",
      "```\n",
      "{{content_fragment}}\n",
      "```注意，只按照要求的输出格式进行输出\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process done 1 / 5\n",
      "sleeping ...... 3 seconds\n",
      "process done 2 / 5\n",
      "sleeping ...... 3 seconds\n",
      "process done 3 / 5\n",
      "sleeping ...... 3 seconds\n",
      "process done 4 / 5\n",
      "sleeping ...... 3 seconds\n",
      "process done 5 / 5\n",
      "sleeping ...... 3 seconds\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import time\n",
    "import traceback\n",
    "# kg_template_file = \"./kg/kg_industry_ana.txt\"\n",
    "template_str = open(kg_template_file).read()\n",
    "print(template_str)\n",
    "import jinja2\n",
    "environment = jinja2.Environment()\n",
    "template = environment.from_string(template_str)\n",
    "\n",
    "content = open('data.txt').read()\n",
    "# print(content) \n",
    "template_count = count_string_tokens(template_str)\n",
    "OPENAI_MAX_TOKEN = 10396 - 300\n",
    "content_token_count = OPENAI_MAX_TOKEN - template_count - 700\n",
    "# print(f\"template count is {template_count}, conent_count is {content_token_count}\")\n",
    "\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "text_spliter = CharacterTextSplitter(\n",
    "        separator=\"\\n\", chunk_size=content_token_count, chunk_overlap=100, length_function=len\n",
    "    )\n",
    "# print(para)\n",
    "tmp_para_list = text_spliter.split_text(content)\n",
    "# print(len(tmp_para_list))\n",
    "tmp_title_list = []\n",
    "tmp_meta_list = []\n",
    "index = 0\n",
    "num_para = len(tmp_para_list)\n",
    "max_count = -1\n",
    "max_item = ''\n",
    "# kg_input_for_ai_file = 'output/600271.kg_industry_ana_in_{}.txt'\n",
    "# openai_out = 'output/600271.kg_industry_ana.openaiout.jsonl'\n",
    "# openai_raw_out = 'output/600271.kg_industry_ana.openaiout.raw'\n",
    "writer = open(openai_out, \"w\")\n",
    "raw_writer = open(openai_raw_out, \"w\")\n",
    "\n",
    "for para_item in tmp_para_list:\n",
    "    item = template.render(content_fragment=para_item)\n",
    " \n",
    "    \n",
    "    \n",
    "    token_count = count_string_tokens(item)\n",
    "    #if token_count > 0 and token_count < OPENAI_MAX_TOKEN:\n",
    "    if token_count > 0 :\n",
    "        open(kg_input_for_ai_file.format(index), \"w\").write(item)\n",
    "        \n",
    "        data = get_completion_from_messages(create_msg(item), model='gpt-3.5-turbo-16k-0613')\n",
    "        try:\n",
    "            raw_writer.write(f\"{index}\\n\\n\" + data + \"\\n\\n\\n\")\n",
    "            \n",
    "            writer.write(json.dumps({\"data\": data}, ensure_ascii=False) + \"\\n\")\n",
    "            print(f\"process done {index+1} / {num_para}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            traceback.print_exc()\n",
    "            print(data)\n",
    "            print(e)\n",
    "            print(f\"process wrong {index+1} / {num_para}\")\n",
    "        print(\"sleeping ...... 3 seconds\")\n",
    "        time.sleep(30)\n",
    "        index += 1 \n",
    "    if token_count > max_count:\n",
    "        max_count = token_count\n",
    "        max_item = item\n",
    "        \n",
    "# print(f\"MAX TOKEN COUNT IS {max_count}\")\n",
    "# print(max_item)\n",
    "print(len(tmp_para_list))\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"data\": \"1. 供应商是否比较集中，如果有，管理层对此风险的解释是怎样的\\n   未提及相关内容，暂不分析。\\n\\n2. 客户是否比较集中，如果有，管理层对此风险的解释是怎样的\\n   未提及相关内容，暂不分析。\\n\\n3. 头部客户是否有关联公司,如果有，管理层对此风险的解释是怎样的\\n   未提及相关内容，暂不分析。\\n\\n4. 头部供应商是否有关联公司,如果有，管理层对此风险的解释是怎样的\\n   未提及相关内容，暂不分析。\"}\n",
      "\n",
      "{\"data\": \"1. 供应商是否比较集中，如果有，管理层对此风险的解释是怎样的\\n   未提及相关内容，暂不分析。\\n\\n2. 客户是否比较集中，如果有，管理层对此风险的解释是怎样的\\n   未提及相关内容，暂不分析。\\n\\n3. 头部客户是否有关联公司,如果有，管理层对此风险的解释是怎样的\\n   未提及相关内容，暂不分析。\\n\\n4. 头部供应商是否有关联公司,如果有，管理层对此风险的解释是怎样的\\n   未提及相关内容，暂不分析。\"}\n",
      "\n",
      "{\"data\": \"1. 供应商是否比较集中，如果有，管理层对此风险的解释是怎样的\\n   公司前五名供应商采购额占年度采购总额的24.23%，其中无关联方采购额占比为100%。管理层未提及供应商集中风险的解释。\\n\\n2. 客户是否比较集中，如果有，管理层对此风险的解释是怎样的\\n   公司前五名客户销售额占年度销售总额的31.48%，其中无关联方销售额占比为0%。管理层未提及客户集中风险的解释。\\n\\n3. 头部客户是否有关联公司，如果有，管理层对此风险的解释是怎样的\\n   管理层未提及头部客户是否有关联公司的情况。\\n\\n4. 头部供应商是否有关联公司，如果有，管理层对此风险的解释是怎样的\\n   管理层未提及头部供应商是否有关联公司的情况。\"}\n",
      "\n",
      "{\"data\": \"1. 供应商是否比较集中，如果有，管理层对此风险的解释是怎样的\\n   公司前五名供应商采购额占年度采购总额的24.23%，其中无关联方采购额占比为100%。管理层未提及供应商集中风险的解释。\\n\\n2. 客户是否比较集中，如果有，管理层对此风险的解释是怎样的\\n   公司前五名客户销售额占年度销售总额的31.48%，其中无关联方销售额占比为0%。管理层未提及客户集中风险的解释。\\n\\n3. 头部客户是否有关联公司，如果有，管理层对此风险的解释是怎样的\\n   管理层未提及头部客户是否有关联公司的情况。\\n\\n4. 头部供应商是否有关联公司，如果有，管理层对此风险的解释是怎样的\\n   管理层未提及头部供应商是否有关联公司的情况。\"}\n",
      "\n",
      "{\"data\": \"1. 供应商是否比较集中，如果有，管理层对此风险的解释是怎样的\\n   未提及相关内容，暂不分析。\\n\\n2. 客户是否比较集中，如果有，管理层对此风险的解释是怎样的\\n   未提及相关内容，暂不分析。\\n\\n3. 头部客户是否有关联公司，如果有，管理层对此风险的解释是怎样的\\n   未提及相关内容，暂不分析。\\n\\n4. 头部供应商是否有关联公司，如果有，管理层对此风险的解释是怎样的\\n   未提及相关内容，暂不分析。\"}\n",
      "\n",
      "{\"data\": \"1. 供应商是否比较集中，如果有，管理层对此风险的解释是怎样的\\n   未提及相关内容，暂不分析。\\n\\n2. 客户是否比较集中，如果有，管理层对此风险的解释是怎样的\\n   未提及相关内容，暂不分析。\\n\\n3. 头部客户是否有关联公司，如果有，管理层对此风险的解释是怎样的\\n   未提及相关内容，暂不分析。\\n\\n4. 头部供应商是否有关联公司，如果有，管理层对此风险的解释是怎样的\\n   未提及相关内容，暂不分析。\"}\n",
      "\n",
      "{\"data\": \"1. 供应商是否比较集中，如果有，管理层对此风险的解释是怎样的\\n   未提及相关内容，暂不分析。\\n\\n2. 客户是否比较集中，如果有，管理层对此风险的解释是怎样的\\n   未提及相关内容，暂不分析。\\n\\n3. 头部客户是否有关联公司,如果有，管理层对此风险的解释是怎样的\\n   未提及相关内容，暂不分析。\\n\\n4. 头部供应商是否有关联公司,如果有，管理层对此风险的解释是怎样的\\n   未提及相关内容，暂不分析。\"}\n",
      "\n",
      "{\"data\": \"1. 供应商是否比较集中，如果有，管理层对此风险的解释是怎样的\\n   未提及相关内容，暂不分析。\\n\\n2. 客户是否比较集中，如果有，管理层对此风险的解释是怎样的\\n   未提及相关内容，暂不分析。\\n\\n3. 头部客户是否有关联公司,如果有，管理层对此风险的解释是怎样的\\n   未提及相关内容，暂不分析。\\n\\n4. 头部供应商是否有关联公司,如果有，管理层对此风险的解释是怎样的\\n   未提及相关内容，暂不分析。\"}\n",
      "\n",
      "{\"data\": \"1. 供应商是否比较集中，如果有，管理层对此风险的解释是怎样的\\n   公司未提及供应商集中风险，暂不分析。\\n\\n2. 客户是否比较集中，如果有，管理层对此风险的解释是怎样的\\n   公司未提及客户集中风险，暂不分析。\\n\\n3. 头部客户是否有关联公司,如果有，管理层对此风险的解释是怎样的\\n   公司未提及头部客户有关联公司的风险，暂不分析。\\n\\n4. 头部供应商是否有关联公司,如果有，管理层对此风险的解释是怎样的\\n   公司未提及头部供应商有关联公司的风险，暂不分析。\"}\n",
      "\n",
      "{\"data\": \"1. 供应商是否比较集中，如果有，管理层对此风险的解释是怎样的\\n   公司未提及供应商集中风险，暂不分析。\\n\\n2. 客户是否比较集中，如果有，管理层对此风险的解释是怎样的\\n   公司未提及客户集中风险，暂不分析。\\n\\n3. 头部客户是否有关联公司,如果有，管理层对此风险的解释是怎样的\\n   公司未提及头部客户有关联公司的风险，暂不分析。\\n\\n4. 头部供应商是否有关联公司,如果有，管理层对此风险的解释是怎样的\\n   公司未提及头部供应商有关联公司的风险，暂不分析。\"}\n",
      "\n",
      "1437\n",
      "根据以上专家的描述和分析，可以得出以下结论：\n",
      "\n",
      "1. 供应商方面，根据第2位专家的信息，公司前五名供应商采购额占年度采购总额的24.23%，其中无关联方采购额占比为100%。管理层未提及供应商集中风险的解释。\n",
      "\n",
      "2. 客户方面，根据第2位专家的信息，公司前五名客户销售额占年度销售总额的31.48%，其中无关联方销售额占比为0%。管理层未提及客户集中风险的解释。\n",
      "\n",
      "3. 关于头部客户和供应商是否有关联公司的风险，所有专家均未提及相关内容，因此无法进行分析。\n",
      "\n",
      "综上所述，根据第2位专家提供的具体信息，公司存在供应商和客户集中的风险，但管理层未提及对这些风险的解释。\n"
     ]
    }
   ],
   "source": [
    "## merge\n",
    "lines = open(openai_out, 'r').readlines()\n",
    "data = []\n",
    "for line in lines:\n",
    "    print(line)\n",
    "    try:\n",
    "        print(line)\n",
    "        item_info = json.loads(line.strip())\n",
    "        data.append(item_info['data'])\n",
    "    except:\n",
    "        traceback.print_exc()\n",
    "        continue\n",
    "    # result = {}\n",
    "    # for item in item_info_list:\n",
    "    #     for key, value in item.items():\n",
    "    #         if len(value) <20 and (value.find(\"未提及\") != -1 or value.find(\"不适用\") != -1):\n",
    "    #             continue\n",
    "    #         else:\n",
    "    #             result[key] = value\n",
    "    #             print(key, value)\n",
    "    # if len(result) > 0:\n",
    "        # data.append(result)\n",
    "# openai_merge_out = 'output/600271.kg_industry_ana.openaiout.merge.jsonl'\n",
    "# openai_merge_raw_out = 'output/600271.kg_industry_ana.openaiout.merge.raw'\n",
    "writer = open(openai_merge_out, 'w')\n",
    "raw_writer = open(openai_merge_raw_out, \"w\")\n",
    "# kg_merge_template_file = \"./kg/kg_industry_ana_merge.txt\"\n",
    "template_str = open(kg_merge_template_file).read()\n",
    "import jinja2\n",
    "environment = jinja2.Environment()\n",
    "template = environment.from_string(template_str)\n",
    "prompts = template.render(enumerate=enumerate, lines=data)\n",
    "# print(prompts)\n",
    "open(kg_merge_input_for_ai_file, 'w').write(prompts)\n",
    "print(count_string_tokens(prompts))\n",
    "\n",
    "data = get_completion_from_messages(create_msg(prompts), model='gpt-3.5-turbo-16k-0613')\n",
    "try:\n",
    "    print(data)\n",
    "    raw_writer.write(f\"{index}\\n\\n\" + data + \"\\n\\n\\n\")\n",
    "    raw_writer.close()\n",
    "    # data_str = json.loads(data)\n",
    "    writer.write(json.dumps({\"data\": data }, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "            \n",
    "except Exception as e:\n",
    "    traceback.print_exc()\n",
    "    print(e)\n",
    "    print(f\"process wrong {index+1} / {num_para}\")\n",
    "writer.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 报告生成"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
