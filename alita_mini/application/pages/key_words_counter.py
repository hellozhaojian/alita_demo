import streamlit as st
from pathlib import Path
import os
from alita_mini.data.data_config import DataLoadingConfig
from alita_mini.adapter.mongo_client import MongoClient
from alita_mini.adapter.redis_client import RedisCache, RedisClient
from alita_mini.data.service.words_counter import WordCounterStat
import streamlit.components.v1 as components
import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import altair as alt


# from streamlit import caching


def app():
    st.title("chaggptæ‘˜è¦")


st.write("# å…¬å‘Šè¯é¢‘ç»Ÿè®¡å·¥å…·ç®±! ğŸ‘‹")


st.markdown(
    """
    è¾“å…¥è¯æ±‡ç»Ÿè®¡ç®¡ç†å±‚åˆ†æä¸­å‡ºç°çš„è¯„ç‡ï¼Œ è¯çš„æ ¼å¼ 
    
    * ä¸€èˆ¬and ç»„åˆï¼Œ ä¾‹å¦‚ â€œ800g å…‰æ¨¡å—"
    * æ”¯æŒè¯ç»„ [å…‰æ¨¡å—|å…‰ç»„ä»¶]
    * æ”¯æŒå¦å®š !è¡Œä¸šå…‰æ¨¡å—
"""
)
# from alita_mini.application.templates import search_result
st.markdown(
    """
   å…¬å‘Š CTR+F åŒ¹é…
"""
)

import asyncio

# loop = asyncio.get_event_loop()


@st.cache_resource
def get_search_service():
    root_dir = Path(os.path.join(os.path.dirname(os.path.abspath(__file__)), "..", "..", ".."))
    # init config
    config_file = root_dir / "scripts" / "config" / "load_data_config.yml"

    config = DataLoadingConfig.load(config_file)
    try:
        loop = asyncio.get_event_loop()
    except:
        loop = asyncio.new_event_loop()

    MongoClient.instance().build(config, loop)
    RedisClient.instance().build(config.redis_config)
    RedisCache.instance().build(config.redis_config, RedisClient.instance())

    word_countet_stat = WordCounterStat(config)
    word_countet_stat.build_index()
    return word_countet_stat


if __name__ == "__main__":
    # caching.clear_cache()
    doc_type = st.sidebar.selectbox("æ–‡æ¡£ç±»å‹", ["å…¬å‘Š"])
    content_type = st.sidebar.selectbox("å†…å®¹ç±»å‹", ["ç®¡ç†å±‚åˆ†æ"])
    # Set report_year variable
    report_year = st.sidebar.selectbox("Report Year", ["2023", "2022", "2021", "2020", "2019"])
    doc_sub_type = st.sidebar.selectbox("æŠ¥å‘Šç±»å‹", ["å¹´æŠ¥", "åŠå¹´æŠ¥"])
    counter_service = get_search_service()
    # å†å²æœç´¢è®°å½•
    st.sidebar.header("å†å²è®°å½•")
    history = counter_service.get_latest_search_keys()
    if history is None or len(history) == 0:
        history = ["800g å…‰æ¨¡å—"]
    selected_history = st.sidebar.selectbox("", history)

    input_value = st.empty()
    if selected_history:
        query = input_value.text_input("è¾“å…¥æ¡†", value=selected_history)
    # query = st.text_input("å…³é”®è¯ï¼š")

    search_button = st.button("æœç´¢")

    if search_button:
        df, cost_time = counter_service.search(
            query=query,
            doc_sub_type=doc_sub_type,
            doc_type=doc_type,
            content_type=content_type,
            report_year=report_year,
            need_streamlit_bar=True,
        )
        st.write(f" COST {cost_time:.2f} ç§’")
        # å¯¹dfæŒ‰'åŒ¹é…æ¬¡æ•°'åˆ—è¿›è¡Œæ’åºï¼Œå–å‰20ä¸ª
        df_sorted = df.sort_values(by="åŒ¹é…æ¬¡æ•°", ascending=False).head(20)

        # åˆ›å»ºä¸€ä¸ªäº¤äº’å¼çš„æŸ±çŠ¶å›¾
        chart = alt.Chart(df_sorted).mark_bar().encode(x="è‚¡ç¥¨ä»£ç ", y="åŒ¹é…æ¬¡æ•°", tooltip=["è‚¡ç¥¨ä»£ç ", "åŒ¹é…æ¬¡æ•°"]).interactive()

        # åœ¨Streamlitä¸­æ˜¾ç¤ºå›¾è¡¨
        st.altair_chart(chart)

        # æ·»åŠ åºå·åˆ—
        df_sorted["åºå·"] = range(1, len(df_sorted) + 1)

        # é‡æ’åˆ—åˆ—
        df_sorted = df_sorted[["åºå·", "è‚¡ç¥¨ä»£ç ", "åŒ¹é…æ¬¡æ•°", "URL"]]

        # ç”ŸæˆåŒ…å«é“¾æ¥çš„HTMLè¡¨æ ¼
        def make_clickable(val):
            # å°†urlè½¬æ¢ä¸ºhtmlé“¾æ¥
            return '<a href="{}">{}</a>'.format(val, "å…¬å‘Šåœ°å€")

        df_sorted["URL"] = df["URL"].apply(make_clickable)

        # df_sorted.style.format({"URL": make_clickable})
        # st.dataframe(df_sorted)

        # å°†æ•°æ®å¸§è½¬æ¢ä¸ºHTMLè¡¨æ ¼
        html_table = df_sorted.to_html(escape=False, index=False)

        # åœ¨Streamlitåº”ç”¨ä¸­æ˜¾ç¤ºHTMLè¡¨æ ¼
        st.markdown(html_table, unsafe_allow_html=True)
